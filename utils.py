from collections import Counter
from os import listdir
import csv
import pydasm
from time import time
from random import randint

INSTR_SET = {

    'mov', 'xchg', 'stc', 'clc', 'cmc', 'std', 'cld', 'sti', 'cli', 'push', 'pushf', 'pusha', 'pop', 'popf', 'popa', 'ccombw', 'cwd', 'cwde', 'in', 'out', 'add', 'adc', 'sub', 'sbb', 'div', 'idiv', 'mul', 'imul', 'inc', 'dec', 'cmp', 'sal', 'sar', 'rcl', 'rcr', 'rol', 'ror', 'neg', 'not', 'and', 'or', 'xor', 'shl', 'shr', 'nop', 'lea', 'int', 'call', 'jmp', 'je', 'jz', 'jcxz', 'jp', 'jpe', 'ja', 'jae', 'jb', 'jbe', 'jna', 'jnae', 'jnb', 'jnbe', 'jc', 'jnc', 'ret', 'jne', 'jnz', 'jecxz', 'jnp', 'jpo', 'jg', 'jge', 'jl', 'jle', 'jng', 'jnge', 'jnl', 'jnle', 'jo', 'jno', 'js', 'jns', 'jns', 'popa', 'rol', 'popf', 'jnz', 'imul', 'lds', 'jna', 'jng', 'jno', 'jnl', 'arpl', 'cli', 'cld', 'clc', 'add', 'adc', 'scasd', 'scasb', 'daa', 'mov', 'das', 'nop', 'repne', 'jnc', 'cmc', 'leave', 'jmpf', 'cmp', 'hlt', 'loope', 'pusha', 'pushf', 'out', 'xor', 'sub', 'rep', 'ret', 'jecxz', 'xchg', 'cwd', 'lea', 'jz', 'jp', 'js', 'jl', 'jo', 'jg', 'ja', 'jc', 'sbb', 'sahf', 'stosb', 'movsd', 'movsb', 'les', 'xlat', 'or', 'into', 'bound', 'pop', 'fildl', 'retf', 'retn', 'fadds', 'faddl', 'call', 'wait', 'sldt', 'fiaddl', 'jmp', 'int1', 'int3', 'std', 'aad', 'aaa', 'stc', 'aam', 'sti', 'aas', 'lahf', 'dec', 'loop', 'and', 'jpo', 'int', 'lock', 'in', 'flds', 'fldl', 'cbw', 'fild', 'inc', 'cmpsb', 'callf', 'cmpsd', 'test', 'fiadd', 'stosd', 'insb', 'outsv', 'iret', 'outsb', 'insv', 'loopne', 'salc', 'lodsb', 'lodsd', 'enter', 'push'
}

UNKNOWN = "unk"
labels_file = "trainLabels.csv"
benign_label = 0
dll_disassemble_suf = ".dlldisassemble"


def get_opcodes_from_asm_file(file_path):
    """
    Reads the disassembly file and extracts all the opcodes used.
    (opcodes that counts are those in INSTR_SET)
    :param file_path: The path to the asm file
    :return: A list with all the opcodes from INSTR_SET (as str) in the file
    """
    opcodes = []
    for line in file(file_path):
        if not line.startswith(".text") and not line.startswith("CODE"):
            continue
        line = line.split()
        if len(line) < 3:  # no opcode
            continue
        for s in line[1:]:
            if s in INSTR_SET:
                opcodes.append(s)
                break
            elif s == ';':
                break

    return opcodes


def make_ngrams(opcodes, n):
    """
    Make a n-sized tuple of opcodes serially, e.g if n = 4 then (opcodes[0], opcodes[1], opcodes[2], opcodes[3]) will be
        the first, and the second will be (opcodes[1], opcodes[2], opcodes[3], opcodes[4]) and so on...
    :param opcodes: A list of opcodes
    :param n: The size of tuples to make
    :return: A list of n sized tuples
    """
    return [tuple(opcodes[i:i + n]) for i in xrange(len(opcodes) - n)]


def get_all_possible_ngrams_from_files(ngrams_lists, ns, use_unknown=True, unknown_precent=0.01):
    """
    Given all the ngrams used in all the training files, finds out which ngrams are used and gives them a unique index.
    :param ngrams_lists: A dict that maps from n to a list,  where the i-th element in the list is a list that contains
        the ngrams (of the specific n) for the i-th file.
    :type ngrams_lists: dict
    :param ns: A list of the "n"s that are used for ngrams.
    :param use_unknown: If True, then an "unknown ngram" token will be added (and given a unique index) for ngrams
        not found in the training files. Also a some of the least common ngrams will be replaced with the
        "unknown ngram" token for training purposes.
    :param unknown_precent: A number between 0 to 1, that indicates what part of all the ngrams is considered not common
    :return: ngrams_sets, i2ngram, ngram2i where:
        * ngrams_sets is a dict that maps from n to a set of all the ngrams used (n-sized)
        * i2ngram is a list of all the ngrams used (without those "unknown" to us) (name means that given an index
            return a ngram)
        * ngram2i is a dict that maps an ngram to its unique index in i2ngram list (given a ngram return index)
    """
    ngrams_lists = {n: [ngram for f in l for ngram in f]
                    for n, l in ngrams_lists.iteritems()}
    ngrams_sets = {n: set(l) for n, l in ngrams_lists.iteritems()}

    if use_unknown:
        counters = Counter([ngram for n in ns for ngram in ngrams_lists[n]])
        not_used = counters.most_common(
        )[:int(-unknown_precent * len(counters)) - 1:-1]
        for ngram in not_used:
            n = len(ngram[0])
            ngrams_sets[n].discard(ngram[0])

    i2ngram = [ngram for n in sorted(list(ngrams_sets.keys()))
               for ngram in sorted(list(ngrams_sets[n]))]
    if use_unknown:
        i2ngram.append(UNKNOWN)
    ngram2i = {ngram: i for i, ngram in enumerate(i2ngram)}
    return ngrams_sets, i2ngram, ngram2i


def make_ngram_counters_for_files(ngrams_lists, ngram_sets, i2ngram, ngram2i, ns, use_unknown=True):
    """
    For each file, counts how many time a certain ngram is used.
    :param ngrams_lists: A dict that maps from n to a list,  where the i-th element in the list is a list that contains
        the ngrams (of the specific n) for the i-th file.
    :param i2ngram: A list of all the ngrams used (without those "unknown" to us) (name means that given an index
        return a ngram)
    :param ngram2i: A dict that maps an ngram to its unique index in i2ngram list (given a ngram return index)
    :param ngram_sets: A dict that maps from n to a set of all the ngrams used (n-sized)
    :type ngram_sets: dict
    :param ns: A list of the "n"s that are used for ngrams.
    :param use_unknown: If True, then an "unknown ngram" token will be added (and given a unique index) for ngrams
        not found in the training files. Also a some of the least common ngrams will be replaced with the
        "unknown ngram" token for training purposes.
    :return: A list, where element #i is a list of counters that counts how many time an ngram is used (indexes matches
        i2ngram) for i-th file (in ngrams_lists)
    """
    num_files = len(ngrams_lists[ns[0]])
    features = []
    for i in xrange(num_files):
        file_features = [0] * len(i2ngram)
        for n in ns:
            for ngram in ngrams_lists[n][i]:
                index = ngram2i[ngram] if not use_unknown or ngram in ngram_sets[n] else ngram2i[UNKNOWN]
                file_features[index] += 1
        features.append(file_features)
    return features


def get_malware_files_features_and_labels(path_to_folder, ns, use_unknown=True, unknown_rate=0.01):
    """
    Reads the malware train files and returns their features and labels
    :param path_to_folder: The folder where the asm files and the labels file are located
    :param ns: A list of the "n"s that are used for ngrams.
    :param use_unknown: If True, then an "unknown ngram" token will be added (and given a unique index) for ngrams
        not found in the training files. Also a some of the least common ngrams will be replaced with the
        "unknown ngram" token for training purposes.
    :param unknown_rate: A number between 0 to 1, that indicates what part of all the ngrams is considered not common
    :return: features, labels, ngrams_sets, i2ngram, ngram2i, labels_dict where:
        * features is a list containing each file's features (a list matching i2ngram that counts how many time a
            ngram is used)
        * labels is a list which holds the label (0-9) of each file. Matches features (i-th element is the same file)
        * ngrams_sets is a dict that maps from n to a set of all the ngrams used (n-sized)
        * i2ngram is a list of all the ngrams used (without those "unknown" to us) (name means that given an index
            return a ngram)
        * ngram2i is a dict that maps an ngram to its unique index in i2ngram list (given a ngram return index)
        * labels_dict is a dictionary that maps between as asm file (without the ".asm" suffix) to it's labels (
            according to the labels file)
    """
    files = listdir(path_to_folder)
    ngrams_list = {n: [] for n in ns}
    labels_dict = {row[0]: row[1] for row in csv.reader(
        open(path_to_folder + "/" + labels_file, "rb"), delimiter=',')}
    labels = []
    for f in files:
        if f.endswith(".asm"):
            opcodes = get_opcodes_from_asm_file(path_to_folder + "/" + f)
            for n in ns:
                ngrams_list[n].append(make_ngrams(opcodes, n))
            labels.append(labels_dict[f[:-4]])

    # now we have a dictionary that maps from an n to a list of ngram partition for each file
    ngrams_sets, i2ngram, ngram2i = get_all_possible_ngrams_from_files(
        ngrams_list, ns, use_unknown, unknown_rate)
    features = make_ngram_counters_for_files(
        ngrams_list, ngrams_sets, i2ngram, ngram2i, ns, use_unknown)

    return features, labels, ngrams_sets, i2ngram, ngram2i, labels_dict


def disassemble_dll(file_path):
    f = open(file_path, "rb")
    buff = f.read()
    f.close()
    instructions = []

    offset = 0
    while offset < len(buff):
        i = pydasm.get_instruction(buff[offset:], pydasm.MODE_32)
        if not i:
            break
        instructions.append(pydasm.get_instruction_string(
            i, pydasm.FORMAT_INTEL, 0))
        offset += i.length
    return instructions


def get_opcodes_of_disassembly_list(disassembly):
    opcodes = []
    for instr in disassembly:
        if instr:
            split = instr.split()
            for op in split:
                if op in INSTR_SET:
                    opcodes.append(op)
                    break
    return opcodes


def disassemble_to_file(file_path, new_file_name):
    dis = disassemble_dll(file_path)
    with open(new_file_name, "w") as f:
        for instruction in dis:
            f.write(instruction + "\n")
    return dis


def get_all_files_features_and_labels(path_to_malware_folder, path_to_benign_folder, ns, use_unknown=True,
                                      unknown_rate=0.01):
    print("start load  data")
    # read malware
    files = listdir(path_to_malware_folder)
    ngrams_list = {n: [] for n in ns}
    labels_dict = {row[0]: int(row[1]) for row in csv.reader(open(path_to_malware_folder + "/" + labels_file, "rb"),
                                                             delimiter=',') if row[1] != "Class"}
    labels = []
    for f in files:
        if f.endswith(".asm"):
            opcodes = get_opcodes_from_asm_file(
                path_to_malware_folder + "/" + f)
            for n in ns:
                ngrams_list[n].append(make_ngrams(opcodes, n))
            labels.append(labels_dict[f[:-4]])

    # read benign
    files = listdir(path_to_benign_folder)
    for f in files:
        if f.endswith(".bytes"):
            if f[:-6] + dll_disassemble_suf not in files:
                temp = disassemble_to_file(path_to_benign_folder + "/" + f, path_to_benign_folder + "/" + f[:-6] +
                                           dll_disassemble_suf)
            else:
                temp = [line[:-1] for line in file(path_to_benign_folder + "/" + f[:-6] + dll_disassemble_suf) if
                        line !=
                        "\n"]
            opcodes = get_opcodes_of_disassembly_list(temp)
            for n in ns:
                ngrams_list[n].append(make_ngrams(opcodes, n))
            labels.append(benign_label)

    # get features, labels and other stuff
    ngrams_sets, i2ngram, ngram2i = get_all_possible_ngrams_from_files(
        ngrams_list, ns, use_unknown, unknown_rate)
    features = make_ngram_counters_for_files(
        ngrams_list, ngrams_sets, i2ngram, ngram2i, ns, use_unknown)

    return features, labels, ngrams_sets, i2ngram, ngram2i, labels_dict


def seperate_to_train_and_test(features, labels, test_size=0.2, num_of_classes=10):
    test_len = int(len(features)*test_size)
    n = int(test_len/num_of_classes)
    train_ftr = list(features)
    train_lbl = list(labels)
    test_ftr = []
    test_lbl = []
    for i in range(0, num_of_classes):
        c = 0
        for x, y in zip(features, labels):
            if y == i:
                test_ftr.append(x)
                test_lbl.append(y)
                c += 1
                if c == n:
                    break
    # delete test from ftr
    for x, y in zip(test_ftr, test_lbl):
        train_ftr.remove(x)
        train_lbl.remove(y)

    # the remaining elements
    sub_len = test_len-len(test_ftr)
    for i in range(0, sub_len):
        temp = randint(0, len(train_ftr)-1)
        test_ftr.append(train_ftr[temp])
        test_lbl.append(train_lbl[temp])
        del train_ftr[temp]
        del train_lbl[temp]
    return train_ftr, test_ftr, train_lbl, test_lbl


# tests of utils functions
if __name__ == '__main__':
    start = time()
    x, y, sets, i2n, n2i, l_dict = get_all_files_features_and_labels(
        "./files/train50", "./files/benign50", [4])
    print len(i2n)
    print len(x[0])
    print[i for i, a in enumerate(x[0]) if a > 0]
    print y[0]
    print "took {} seconds".format(time()-start)
    pass
